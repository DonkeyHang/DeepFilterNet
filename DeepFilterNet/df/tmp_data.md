step:0

# input tensor
print(all_spec_float[:,:,0:2,0:5,:])
tensor([[[[[ 3.0110e-01,  0.0000e+00],
           [-1.2907e-01,  2.0222e-01],
           [-2.5161e-02, -1.1091e-01],
           [ 3.0015e-03,  4.3966e-02],
           [ 8.7744e-04, -4.1078e-02]],

          [[ 6.0219e-01,  0.0000e+00],
           [-2.5681e-01, -8.4042e-04],
           [-5.1772e-02, -3.3885e-04],
           [ 6.8657e-03,  6.7406e-05],
           [ 6.7928e-04,  8.8922e-06]]]]])

print(all_erb_feat[:,:,0:2,0:5])
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0994, -0.2128, -0.9856, -2.0277, -2.5642]]]])

print(all_spec_feat[:,:,0:2,0:5,:])
tensor([[[[[ 0.5487,  0.0000],
           [ 0.2354,  0.4339],
           [ 0.2104, -0.2662],
           [ 0.1534,  0.1447],
           [ 0.1448, -0.1432]],

          [[ 1.0920,  0.0000],
           [-0.2617,  0.4639],
           [-0.0970, -0.1213],
           [ 0.0245, -0.0222],
           [ 0.0024,  0.0024]]]]])


# debug in model
print(e0[:,0:2,0:2,0:2])
tensor([[[[0.0000, 0.0000],
          [0.0000, 0.0000]],

         [[0.0731, 0.0731],
          [0.0863, 0.3093]]]], grad_fn=<SliceBackward0>)

print(e1[:,0:2,0:2,0:2])
tensor([[[[0.0000, 0.0360],
          [0.0000, 0.0000]],

         [[0.0637, 0.0325],
          [0.0000, 0.0000]]]], grad_fn=<SliceBackward0>)

print(e2[:,0:2,0:2,0:2])
tensor([[[[0.0000, 0.0553],
          [0.0499, 2.5906]],

         [[0.0410, 0.2877],
          [0.0000, 0.0000]]]], grad_fn=<SliceBackward0>)

print(e3[:,0:2,0:2,0:2])
tensor([[[[0.0000, 0.0941],
          [0.0000, 0.0000]],

         [[0.0000, 0.0000],
          [1.1036, 5.9855]]]], grad_fn=<SliceBackward0>)

print(emb[:,0:2,0:5])
tensor([[[0.0803, 0.0188, 0.1478, 0.0927, 0.0799],
         [0.0618, 0.0295, 0.0000, 0.0086, 0.1827]]], grad_fn=<SliceBackward0>)

print(c0[:,0:2,0:2,0:2])
tensor([[[[0.4897, 0.4832],
          [0.0000, 0.0000]],

         [[0.0000, 0.0000],
          [0.0000, 0.0000]]]], grad_fn=<SliceBackward0>)

print(m[:,:,0:2,0:5])
tensor([[[[0.3291, 0.3678, 0.4199, 0.3571, 0.3274],
          [0.2684, 0.3449, 0.3118, 0.1856, 0.2656]]]],
       grad_fn=<SliceBackward0>)

print(spec_m[:,:,0:2,0:5,:])
tensor([[[[[ 9.9102e-02,  0.0000e+00],
           [-4.2481e-02,  6.6558e-02],
           [-9.2547e-03, -4.0793e-02],
           [ 1.1040e-03,  1.6171e-02],
           [ 3.6839e-04, -1.7247e-02]],

          [[ 1.6163e-01,  0.0000e+00],
           [-6.8929e-02, -2.2557e-04],
           [-1.7855e-02, -1.1686e-04],
           [ 2.3678e-03,  2.3246e-05],
           [ 2.1182e-04,  2.7729e-06]]]]], grad_fn=<SliceBackward0>)

print(df_coefs[:,0:2,0:3,0:3])
tensor([[[[-1.0465e-02,  7.5760e-04,  1.7294e-02],
          [ 4.2580e-03,  5.0644e-04, -4.3625e-03],
          [ 4.0559e-03, -3.8791e-04, -9.5590e-03]],

         [[-6.7547e-03,  1.1750e-03, -3.4227e-03],
          [-6.0391e-05, -1.6496e-03, -4.7214e-03],
          [ 4.1061e-05, -2.2541e-03,  1.4348e-03]]]], grad_fn=<SliceBackward0>)

print(df_coefs[:,0:2,0:2,0:3,:])
tensor([[[[[-1.0465e-02,  7.5760e-04],
           [ 4.2580e-03,  5.0644e-04],
           [ 4.0559e-03, -3.8791e-04]],

          [[-6.7547e-03,  1.1750e-03],
           [-6.0391e-05, -1.6496e-03],
           [ 4.1061e-05, -2.2541e-03]]],


         [[[ 1.7294e-02,  1.2559e-03],
           [-4.3625e-03,  1.7017e-02],
           [-9.5590e-03, -1.0819e-04]],

          [[-3.4227e-03,  1.0395e-03],
           [-4.7214e-03,  1.9915e-03],
           [ 1.4348e-03, -5.6585e-03]]]]], grad_fn=<SliceBackward0>)

# =====================
# jump into self.df_op

print(spec_u[:,:,0:2,0:5,0:2])
tensor([[[[[ 0.0000+0.0000j,  0.0000+0.0000j],
           [ 0.0000+0.0000j,  0.0000+0.0000j],
           [ 0.0000+0.0000j,  0.0000+0.0000j],
           [ 0.0000+0.0000j,  0.0000+0.0000j],
           [ 0.0000+0.0000j,  0.0000+0.0000j]],

          [[ 0.0000+0.0000j,  0.3011+0.0000j],
           [ 0.0000+0.0000j, -0.1291+0.2022j],
           [ 0.0000+0.0000j, -0.0252-0.1109j],
           [ 0.0000+0.0000j,  0.0030+0.0440j],
           [ 0.0000+0.0000j,  0.0009-0.0411j]]]]])

print(coefs[:,0:2,0:2,0:5])
tensor([[[[-1.0465e-02+7.5760e-04j,  4.2580e-03+5.0644e-04j,
            4.0559e-03-3.8791e-04j, -1.0280e-03+2.8933e-03j,
           -3.3722e-04+1.0964e-03j],
          [-6.7547e-03+1.1750e-03j, -6.0391e-05-1.6496e-03j,
            4.1061e-05-2.2541e-03j,  2.3262e-03+8.3752e-04j,
            4.2860e-04-8.9068e-04j]],

         [[ 1.7294e-02+1.2559e-03j, -4.3625e-03+1.7017e-02j,
           -9.5590e-03-1.0819e-04j,  2.9080e-03-1.9701e-03j,
           -1.7358e-04+1.9719e-03j],
          [-3.4227e-03+1.0395e-03j, -4.7214e-03+1.9915e-03j,
            1.4348e-03-5.6585e-03j,  6.7485e-03+2.4245e-04j,
            1.8862e-03+1.9868e-05j]]]], grad_fn=<SliceBackward0>)

print(spec_f[:,:,0:2,0:2,:])
tensor([[[[[ 0.0000+0.0000j,  0.0000+0.0000j,  0.3011+0.0000j,  0.6022+0.0000j,
             0.6022+0.0000j],
           [ 0.0000+0.0000j,  0.0000+0.0000j, -0.1291+0.2022j, -0.2568-0.0008j,
            -0.2568-0.0008j]],

          [[ 0.0000+0.0000j,  0.3011+0.0000j,  0.6022+0.0000j,  0.6022+0.0000j,
             0.6022+0.0000j],
           [ 0.0000+0.0000j, -0.1291+0.2022j, -0.2568-0.0008j, -0.2568-0.0008j,
            -0.2568-0.0008j]]]]])

print(coefs[:,:,0:2,0:2,0:5])
tensor([[[[[-1.0465e-02+7.5760e-04j,  4.2580e-03+5.0644e-04j,
             4.0559e-03-3.8791e-04j, -1.0280e-03+2.8933e-03j,
            -3.3722e-04+1.0964e-03j],
           [-6.7547e-03+1.1750e-03j, -6.0391e-05-1.6496e-03j,
             4.1061e-05-2.2541e-03j,  2.3262e-03+8.3752e-04j,
             4.2860e-04-8.9068e-04j]],

          [[ 1.7294e-02+1.2559e-03j, -4.3625e-03+1.7017e-02j,
            -9.5590e-03-1.0819e-04j,  2.9080e-03-1.9701e-03j,
            -1.7358e-04+1.9719e-03j],
           [-3.4227e-03+1.0395e-03j, -4.7214e-03+1.9915e-03j,
             1.4348e-03-5.6585e-03j,  6.7485e-03+2.4245e-04j,
             1.8862e-03+1.9868e-05j]]]]], grad_fn=<SliceBackward0>)

# =================
# jump into self.df_op_rt




# =================


print(spec_f[:,:,0:2,0:5])
tensor([[[[ 4.8298e-02-1.2339e-04j, -1.1502e-02+2.2533e-02j,
           -3.2143e-04-2.9871e-03j,  3.7882e-05+5.4574e-04j,
            1.0460e-05-5.0504e-04j],
          [ 5.2188e-02-4.0238e-04j, -1.9218e-02-1.0102e-03j,
           -3.7274e-03-3.2040e-04j,  3.1187e-04+2.8062e-04j,
            2.1478e-05-7.9363e-05j]]]], grad_fn=<SliceBackward0>)

print(spec_e[:,:,0:2,0:5,:])
tensor([[[[[ 4.8298e-02, -1.2339e-04],
           [-1.1502e-02,  2.2533e-02],
           [-3.2143e-04, -2.9871e-03],
           [ 3.7882e-05,  5.4574e-04],
           [ 1.0460e-05, -5.0504e-04]],

          [[ 5.2188e-02, -4.0238e-04],
           [-1.9218e-02, -1.0102e-03],
           [-3.7274e-03, -3.2040e-04],
           [ 3.1187e-04,  2.8062e-04],
           [ 2.1478e-05, -7.9363e-05]]]]], grad_fn=<SliceBackward0>)

print(spec_e[:,:,0:2,96:100,:])
tensor([[[[[ 1.1278e-05, -3.4710e-05],
           [-1.1276e-05,  3.4322e-05],
           [ 1.1278e-05, -3.3952e-05],
           [-1.1276e-05,  3.3579e-05]],

          [[-5.3449e-20, -4.2486e-20],
           [-7.0522e-21, -1.4653e-20],
           [ 3.0005e-20,  3.9978e-20],
           [-4.1990e-20,  2.0495e-20]]]]], grad_fn=<SliceBackward0>)




# jump out self.df_op
# =====================
print(spec_e[:,:,0:2,0:3,:])
tensor([[[[[ 0.0483, -0.0001],
           [-0.0115,  0.0225],
           [-0.0003, -0.0030]],

          [[ 0.0522, -0.0004],
           [-0.0192, -0.0010],
           [-0.0037, -0.0003]]]]], grad_fn=<SliceBackward0>)









































# compare for einsum vs rt
# =========================================
# offline

# before jump into self.dp_op
# spec->print(spec.shape):torch.Size([1, 1, 1000, 481, 2])
print(spec[:,:,0:2,0:5,:])
tensor([[[[[ 3.0110e-01,  0.0000e+00],
           [-1.2907e-01,  2.0222e-01],
           [-2.5161e-02, -1.1091e-01],
           [ 3.0015e-03,  4.3966e-02],
           [ 8.7744e-04, -4.1078e-02]],

          [[ 6.0219e-01,  0.0000e+00],
           [-2.5681e-01, -8.4042e-04],
           [-5.1772e-02, -3.3885e-04],
           [ 6.8657e-03,  6.7406e-05],
           [ 6.7928e-04,  8.8922e-06]]]]])

# print(df_coefs.shape):torch.Size([1, 5, 1000, 96, 2])
print(df_coefs[:,0:2,0:2,0:5,:])
tensor([[[[[-1.0465e-02,  7.5760e-04],
           [ 4.2580e-03,  5.0644e-04],
           [ 4.0559e-03, -3.8791e-04],
           [-1.0280e-03,  2.8933e-03],
           [-3.3722e-04,  1.0964e-03]],

          [[-6.7547e-03,  1.1750e-03],
           [-6.0391e-05, -1.6496e-03],
           [ 4.1061e-05, -2.2541e-03],
           [ 2.3262e-03,  8.3752e-04],
           [ 4.2860e-04, -8.9068e-04]]],


         [[[ 1.7294e-02,  1.2559e-03],
           [-4.3625e-03,  1.7017e-02],
           [-9.5590e-03, -1.0819e-04],
           [ 2.9080e-03, -1.9701e-03],
           [-1.7358e-04,  1.9719e-03]],

          [[-3.4227e-03,  1.0395e-03],
           [-4.7214e-03,  1.9915e-03],
           [ 1.4348e-03, -5.6585e-03],
           [ 6.7485e-03,  2.4245e-04],
           [ 1.8862e-03,  1.9868e-05]]]]], grad_fn=<SliceBackward0>)



# jump into self.df_op
# print(spec_u.shape):torch.Size([1, 1, 1000, 481, 5])
print(spec_u[:,:,0:2,0:5,0:2])
tensor([[[[[0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j]],

          [[0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j]]]]])

# print(coefs.shape):torch.Size([1, 5, 1000, 96])
print(coefs[:,0:2,0:2,0:5])
tensor([[[[-1.0465e-02+7.5760e-04j,  4.2580e-03+5.0644e-04j,
            4.0559e-03-3.8791e-04j, -1.0280e-03+2.8933e-03j,
           -3.3722e-04+1.0964e-03j],
          [-6.7547e-03+1.1750e-03j, -6.0391e-05-1.6496e-03j,
            4.1061e-05-2.2541e-03j,  2.3262e-03+8.3752e-04j,
            4.2860e-04-8.9068e-04j]],

         [[ 1.7294e-02+1.2559e-03j, -4.3625e-03+1.7017e-02j,
           -9.5590e-03-1.0819e-04j,  2.9080e-03-1.9701e-03j,
           -1.7358e-04+1.9719e-03j],
          [-3.4227e-03+1.0395e-03j, -4.7214e-03+1.9915e-03j,
            1.4348e-03-5.6585e-03j,  6.7485e-03+2.4245e-04j,
            1.8862e-03+1.9868e-05j]]]], grad_fn=<SliceBackward0>)

# print(spec_f.shape):torch.Size([1, 1, 1000, 96, 5])
print(spec_f[:,:,0:2,0:5,0:2])
tensor([[[[[0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j]],

          [[0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j],
           [0.+0.j, 0.+0.j]]]]])

# print(coefs.shape):torch.Size([1, 1, 5, 1000, 96])
print(coefs[:,:,0:2,0:2,0:5])
tensor([[[[[-1.0465e-02+7.5760e-04j,  4.2580e-03+5.0644e-04j,
             4.0559e-03-3.8791e-04j, -1.0280e-03+2.8933e-03j,
            -3.3722e-04+1.0964e-03j],
           [-6.7547e-03+1.1750e-03j, -6.0391e-05-1.6496e-03j,
             4.1061e-05-2.2541e-03j,  2.3262e-03+8.3752e-04j,
             4.2860e-04-8.9068e-04j]],

          [[ 1.7294e-02+1.2559e-03j, -4.3625e-03+1.7017e-02j,
            -9.5590e-03-1.0819e-04j,  2.9080e-03-1.9701e-03j,
            -1.7358e-04+1.9719e-03j],
           [-3.4227e-03+1.0395e-03j, -4.7214e-03+1.9915e-03j,
             1.4348e-03-5.6585e-03j,  6.7485e-03+2.4245e-04j,
             1.8862e-03+1.9868e-05j]]]]], grad_fn=<SliceBackward0>)

# after einsum
# print(spec_f.shape):torch.Size([1, 1, 1000, 96])
print(spec_f[:,:,0:2,0:5])
tensor([[[[-2.9019e-03+3.4835e-04j, -4.6431e-04+7.3632e-04j,
           -1.4840e-04-3.4351e-04j,  1.1966e-04-5.3502e-05j,
           -5.3113e-05+5.2640e-07j],
          [-4.6601e-03+8.1578e-05j,  1.2055e-03-9.5765e-04j,
            5.4541e-04-1.7077e-04j,  8.8755e-05+2.2027e-04j,
           -1.1387e-04+1.3344e-05j]]]], grad_fn=<SliceBackward0>)


# =========================================
# rt
# before jump into self.dp_op_rt
print(spec[:,:,0:2,0:5,:])  same for offline

print(df_coefs[:,0:2,0:2,0:5,:]) same for offline

# jump into self.df_op_rt
print(spec_u[:,:,0:2,0:2,0:5,0:2]) same for offline

print(spec_f[:,:,0:2,0:2,0:5,0:2]) same for offline

print(coefs[:,:,0:2,0:2,0:5,0:2]) same for offline

print(spec_f[:,:,0:2,0:5,:]) same for offline




# =========================================




























# ==================== step 2 =========================
# all data

# print(feat_erb.shape):torch.Size([1, 1, 1000, 32])
print(feat_erb[:,:,2:4,0:5])
tensor([[[[ 0.0984, -0.2107, -0.9757, -2.0074, -2.5385],
          [ 0.0974, -0.2086, -0.9659, -1.9873, -2.5132]]]])

# print(feat_spec.shape):torch.Size([1, 2, 1000, 96])
print(feat_spec[:,:,2:4,0:5])
tensor([[[[ 1.0867, -0.2660, -0.0978,  0.0246,  0.0024],
          [ 1.0815, -0.2704, -0.0986,  0.0248,  0.0024]],

         [[ 0.0000,  0.4663, -0.1218, -0.0223,  0.0024],
          [ 0.0000,  0.4687, -0.1222, -0.0223,  0.0024]]]])

# print(e0.shape):torch.Size([1, 64, 1000, 32])
print(e0[:,0:4,2:4,0:4])
tensor([[[[0.0000, 0.0000, 0.5629, 2.1031],
          [0.0000, 0.0000, 0.0000, 0.3610]],

         [[0.1198, 0.4950, 0.8007, 0.7181],
          [0.3655, 1.3699, 2.1515, 1.7285]],

         [[0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0655]],

         [[0.4155, 0.7311, 0.7369, 0.0000],
          [0.5973, 1.2422, 1.5332, 0.6232]]]], grad_fn=<SliceBackward0>)


# print(m.shape):torch.Size([1, 1, 1000, 32])
print(m[:,:,2:4,0:4])
tensor([[[[0.2966, 0.3682, 0.2895, 0.0878],
          [0.2302, 0.2405, 0.3358, 0.4029]]]], grad_fn=<SliceBackward0>)

# print(spec_m.shape):torch.Size([1, 1, 1000, 481, 2])
print(spec_m[:,:,2:4,0:4,:])
tensor([[[[[ 1.7861e-01,  0.0000e+00],
           [-7.6168e-02, -2.4926e-04],
           [-1.9062e-02, -1.2476e-04],
           [ 2.5278e-03,  2.4818e-05]],

          [[ 1.3860e-01,  0.0000e+00],
           [-5.9107e-02, -1.9343e-04],
           [-1.2450e-02, -8.1489e-05],
           [ 1.6511e-03,  1.6210e-05]]]]], grad_fn=<SliceBackward0>)

# print(df_coefs.shape):torch.Size([1, 5, 1000, 96, 2])
print(df_coefs[:,0:2,2:4,0:4,:])
tensor([[[[[ 0.0125,  0.0007],
           [ 0.0018, -0.0030],
           [ 0.0107, -0.0050],
           [ 0.0050, -0.0020]],

          [[-0.0144,  0.0024],
           [-0.0028, -0.0041],
           [ 0.0110, -0.0158],
           [ 0.0082, -0.0032]]],


         [[[-0.0099,  0.0022],
           [ 0.0133, -0.0095],
           [ 0.0120,  0.0046],
           [-0.0032, -0.0010]],

          [[-0.0241,  0.0050],
           [ 0.0189, -0.0127],
           [ 0.0135,  0.0114],
           [-0.0123, -0.0023]]]]], grad_fn=<SliceBackward0>)





# realtime



# ==================== step 2 end =========================




























# ===============================
# step 2 Encoder.forward()

# all_data

# print(feat_erb.shape):torch.Size([1, 1, 1000, 32])
print(feat_erb[:,:,:4,0:5])
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0994, -0.2128, -0.9856, -2.0277, -2.5642],
          [ 0.0984, -0.2107, -0.9757, -2.0074, -2.5385],
          [ 0.0974, -0.2086, -0.9659, -1.9873, -2.5132]]]])

# print(feat_spec.shape):torch.Size([1, 2, 1000, 96])
print(feat_spec[:,:,:4,0:5])
tensor([[[[ 0.5487,  0.2354,  0.2104,  0.1534,  0.1448],
          [ 1.0920, -0.2617, -0.0970,  0.0245,  0.0024],
          [ 1.0867, -0.2660, -0.0978,  0.0246,  0.0024],
          [ 1.0815, -0.2704, -0.0986,  0.0248,  0.0024]],

         [[ 0.0000,  0.4339, -0.2662,  0.1447, -0.1432],
          [ 0.0000,  0.4639, -0.1213, -0.0222,  0.0024],
          [ 0.0000,  0.4663, -0.1218, -0.0223,  0.0024],
          [ 0.0000,  0.4687, -0.1222, -0.0223,  0.0024]]]])

# print(e0.shape):torch.Size([1, 64, 1000, 32])
print(e0[:,0:2,:4,0:5])
tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.5629, 2.1031, 2.9221],
          [0.0000, 0.0000, 0.0000, 0.3610, 1.1056]],

         [[0.0731, 0.0731, 0.0731, 0.0731, 0.0731],
          [0.0863, 0.3093, 0.4913, 0.4542, 0.1146],
          [0.1198, 0.4950, 0.8007, 0.7181, 0.1777],
          [0.3655, 1.3699, 2.1515, 1.7285, 0.4145]]]],
       grad_fn=<SliceBackward0>)
